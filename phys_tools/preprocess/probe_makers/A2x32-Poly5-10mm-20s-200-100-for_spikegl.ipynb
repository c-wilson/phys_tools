{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUILD PROBE VIA SITE MAP FROM NN\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "site_groups = {\n",
    "    0: {\n",
    "        'geometry':{\n",
    "        },\n",
    "        'sites': [x for x in range(1, 33)]  # 1 to 33\n",
    "    },\n",
    "    1: {\n",
    "        'geometry': {\n",
    "        },\n",
    "        'sites': [x for x in range(33, 65)]  # 33 to 64\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "row1 = np.arange(1, 7)\n",
    "row2 = np.arange(7, 14)\n",
    "row3 = np.array([14,19,15,18,16,17])\n",
    "row4 = np.flipud(np.arange(20,27))\n",
    "row5 = np.flipud(np.arange(27,33))\n",
    "print (row1.size+row2.size+row3.size+row4.size+row5.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "site_order1 = [7,26,1,14,32,8,25,2,19,31,9,24,3,15,30,10,\n",
    "              23,4,18,29,11,22,5,16,28,12,21,6,17,27,13,20]\n",
    "site_order2 = [x+32 for x in site_order1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 26, 1, 14, 32, 8, 25, 2, 19, 31, 9, 24, 3, 15, 30, 10, 23, 4, 18, 29, 11, 22, 5, 16, 28, 12, 21, 6, 17, 27, 13, 20]\n",
      "[39, 58, 33, 46, 64, 40, 57, 34, 51, 63, 41, 56, 35, 47, 62, 42, 55, 36, 50, 61, 43, 54, 37, 48, 60, 44, 53, 38, 49, 59, 45, 52]\n"
     ]
    }
   ],
   "source": [
    "print (site_order1)\n",
    "print (site_order2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERT TO CHANNELS FROM SITES\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SGL_64 = {\n",
    "    'raw_channels': range(64),\n",
    "    'Neuronexus': [\n",
    "        50, 52, 59, 61, 56, 63, 58, 64, 34, 35, 62, 33, 60, 54, 57, 55, 10, 8, 11, 5, 32, 3, 30, 31, 1, 7, 2,\n",
    "        9, 4, 6, 13, 15, 41, 43, 39, 40, 42, 44, 46, 48, 53, 51, 49, 47, 45, 36, 37, 38, 27, 28, 29, 20, 18,\n",
    "        16, 14, 12, 17, 19, 21, 23, 25, 26, 22, 24\n",
    "    ],\n",
    "    'NanoZ': [\n",
    "        34, 36, 38, 40, 42, 44, 46, 48, 47, 45, 43, 41, 39, 37, 35, 33, 57, 59, 62, 64, 50, 52, 54, 56, 55, 53,\n",
    "        51, 49, 63, 61, 60, 58, 1, 3, 5, 7, 9, 11, 13, 15, 16, 14, 12, 10, 8, 6, 4, 2, 26, 28, 29, 31, 17, 19, 21,\n",
    "        23, 24, 22, 20, 18, 32, 30, 27, 25\n",
    "    ],\n",
    "    'HIRES_4x16_flipchip': [\n",
    "        18, 20, 21, 23, 24, 25, 26, 27, 31, 30, 29, 32, 28, 22, 19, 17, 48, 46, 43, 37, 33, 36, 35, 34, 38, 39, 40, 41,\n",
    "        42, 44, 45, 47, 1, 3, 6, 8, 10, 12, 14, 16, 15, 13, 11, 9, 7, 5, 4, 2, 63, 61, 60, 58, 56, 54, 52, 50, 49, 51,\n",
    "        53, 55, 57, 59, 62, 64\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channel_order1 = list()\n",
    "channel_order2 = list()\n",
    "for ss, cc in zip([site_order1, site_order2], [channel_order1, channel_order2]):\n",
    "    for s in ss:\n",
    "        cc.append(SGL_64['Neuronexus'].index(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 61, 24, 54, 20, 17, 60, 26, 57, 23, 27, 63, 21, 31, 22, 16, 59, 28, 52, 50, 18, 62, 19, 53, 49, 55, 58, 29, 56, 48, 30, 51]\n"
     ]
    }
   ],
   "source": [
    "print(channel_order1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34, 6, 11, 38, 7, 35, 14, 8, 41, 5, 32, 4, 9, 43, 10, 36, 15, 45, 0, 3, 33, 13, 46, 39, 12, 37, 40, 47, 42, 2, 44, 1]\n"
     ]
    }
   ],
   "source": [
    "print(channel_order2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_sites_to_channels(site_groups, acq_channels_numbers, acq_site_mapping):\n",
    "    \"\"\"\n",
    "    This maps sites to channels for geometries and the site lists. Also checks for integrity of site lists.\n",
    "    \n",
    "    site_groups is a dictionary with sites and geometries keys.\n",
    "    acq_channel_numbers is a list of channels in order from the acquistion system (ie a range from 0-63).\n",
    "    acq_site_mapping is a list of site numbers corresponding to the acquisition channel numbers specified above.\n",
    "    \n",
    "    \n",
    "    So this will map:\n",
    "        site_groups {\n",
    "            0: {\n",
    "            'sites': [46,45,44]\n",
    "            }\n",
    "        }\n",
    "        acq_channel_numbers = [1,2,3]\n",
    "        acq_site_mapping = [45, 46, 46]\n",
    "        \n",
    "        to:\n",
    "        site_groups {\n",
    "            0: {\n",
    "            'sites': [3, 2, 1]\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    all_ch = []\n",
    "    for k, v in site_groups.items():\n",
    "        all_ch.extend(v['sites'])\n",
    "    print (\"{0} sites found on all groups.\".format(len(all_ch)))\n",
    "    bad = False\n",
    "    for i in all_ch:\n",
    "        nmatches = 0\n",
    "        for ii in all_ch:\n",
    "            if ii == i:\n",
    "                nmatches += 1\n",
    "        if nmatches >= 2:\n",
    "            print (\"ERROR: duplicate site of number {0} found.\".format(i))\n",
    "            bad = True\n",
    "    if bad:\n",
    "        return None\n",
    "    else:\n",
    "        print (\"No duplicate channels.\")\n",
    "        \n",
    "    for k, v in site_groups.items():\n",
    "        site_list = v['sites']\n",
    "        geo = v['geometry'].keys()\n",
    "        \n",
    "        assert len(site_list) == len(geo)\n",
    "        \n",
    "        for s in site_list:\n",
    "            if s not in geo:\n",
    "                raise ValueError('Site {0} specified in \"sites\" but not in \"geometry\" for shank {1}'.format(s, k))\n",
    "        for s in geo:\n",
    "            if s not in site_list:\n",
    "                raise ValueError('Site {0} specified in \"geometry\" but not \"sites\" for shank {1}'.format(s, k))        \n",
    "    print('Site and geometry lists are congruent.')\n",
    "    \n",
    "    channel_groups = {}\n",
    "    for g, v in site_groups.items():\n",
    "        channel_group = {}\n",
    "        channels = []\n",
    "        geometry = {}\n",
    "        for s in v['sites']:\n",
    "            site_idx = acq_site_mapping.index(s)\n",
    "            ch = acq_channels_numbers[site_idx]\n",
    "            channels.append(ch)\n",
    "        channel_group['channels'] = channels\n",
    "        \n",
    "        for s, pos in v['geometry'].items():\n",
    "            site_idx = acq_site_mapping.index(s)\n",
    "            ch = acq_channels_numbers[site_idx]\n",
    "            geometry[ch] = pos\n",
    "        channel_group['geometry'] = geometry\n",
    "        \n",
    "        graph = []\n",
    "        for edge in v['graph']:\n",
    "            new_edge = []\n",
    "            for node in edge:\n",
    "                new_edge.append(acq_channels_numbers[acq_site_mapping.index(node)])\n",
    "            graph.append(new_edge)\n",
    "        channel_group['graph'] = graph\n",
    "        channel_groups[g] = channel_group\n",
    "        \n",
    "    return channel_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 sites found on all groups.\n",
      "No duplicate channels.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d93e5bffc77f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchannel_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_sites_to_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGL_64\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raw_channels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGL_64\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Neuronexus'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-3b4de3c83db2>\u001b[0m in \u001b[0;36mconvert_sites_to_channels\u001b[0;34m(site_groups, acq_channels_numbers, acq_site_mapping)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mgeo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geometry'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msite_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "channel_groups = convert_sites_to_channels(site_groups, SGL_64['raw_channels'], SGL_64['Neuronexus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open('/home/cdw291/probes/whisper/A2x32-Poly5_whisper.prb', 'w')\n",
    "# pickle.dump(channel_groups, f, 0)\n",
    "f.write(\"channel_groups = {0}\".format(channel_groups.__str__()))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
